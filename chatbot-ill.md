


## ğŸ“Š ä»£ç ä»“åº“åˆ†æã€græŠ¥å‘Š

### ä¸€mini (Gemini) å‚æ•°ä¼ é€’æœºåˆ¶

#### 1. **è°ƒç”¨é“¾è·¯åˆ†æ**

```
ç”¨æˆ·è¾“å…¥ â†’ ChatBot.tsx (UIç»„ä»¶)
                â†“
         sendMessageStream() / createChatSession()
                â†“
         geminiService.ts (æœåŠ¡å±‚)
                â†“
         @google/genai SDK
                â†“
         Gemini API
```

#### 2. **å‚æ•°ä¼ é€’è¯¦è§£**

**ChatBot.tsx â†’ geminiService.ts:**

```typescript
// åˆ›å»ºä¼šè¯æ—¶ä¼ é€’ç³»ç»ŸæŒ‡ä»¤
export const createChatSession = (): Chat => {
  const ai = getAiClient();
  return ai.chats.create({
    model: 'gemini-3-flash',
    config: {
      systemInstruction: SYSTEM_INSTRUCTION,  // ç³»ç»ŸæŒ‡ä»¤å¸¸é‡
      temperature: 0.7,
    },
  });
};

// å‘é€æ¶ˆæ¯æ—¶ä¼ é€’ç”¨æˆ·è¾“å…¥
export const sendMessageStream = async (chat: Chat, message: string) => {
  return chat.sendMessageStream({ message });
};
```

**å…³é”®å‚æ•°ï¼š**

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `message` | string | ç”¨æˆ·è¾“å…¥çš„å¯¹è¯å†…å®¹ |
| `systemInstruction` | string | ç³»ç»Ÿè§’è‰²å®šä¹‰ï¼ˆåœ¨ constants.ts ä¸­ï¼‰ |
| `model` | string | æ¨¡å‹åç§°ï¼ˆgemini-3-flash / gemini-2.0-flashï¼‰ |
| `temperature` | number | 0.7ï¼ˆåˆ›æ„ç¨‹åº¦ï¼‰ |

---

### äºŒã€AI Chatbot èŠå¤©åŠŸèƒ½å®ç°

#### 1. **ChatBot.tsx æ ¸å¿ƒé€»è¾‘**

```typescript
// çŠ¶æ€ç®¡ç†
const [messages, setMessages] = useState<Message[]>([...])
const chatSessionRef = useRef<Chat | null>(null)

// åˆå§‹åŒ–èŠå¤©ä¼šè¯
useEffect(() => {
  chatSessionRef.current = createChatSession()
}, [])

// å‘é€æ¶ˆæ¯å¹¶å¤„ç†æµå¼å“åº”
const handleSend = async () => {
  const streamResult = await sendMessageStream(chatSessionRef.current, userMsg.text)
  for await (const chunk of streamResult) {
    // é€å—æ›´æ–°æ¶ˆæ¯å†…å®¹ï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
  }
}
```

#### 2. **æµå¼å“åº”å¤„ç†**

- ä½¿ç”¨ `sendMessageStream()` å®ç°å®æ—¶æ‰“å­—æœºæ•ˆæœ
- æ¯æ¬¡æ¥æ”¶åˆ° chunk å°±æ›´æ–° UIï¼Œé¿å…ç­‰å¾…å®Œæ•´å“åº”

---

### ä¸‰ã€æ›´æ¢ä¸º MiniMax / GLM API å¯è¡Œæ€§åˆ†æ

#### âœ… **æŠ€æœ¯å¯è¡Œæ€§ï¼šé«˜**

**ä¼˜åŠ¿ï¼š**

1. **SDK ç»“æ„ç›¸ä¼¼** - ä¸»æµ LLM API éƒ½é‡‡ç”¨ç±»ä¼¼çš„è°ƒç”¨æ¨¡å¼
2. **åªéœ€ä¿®æ”¹æœåŠ¡å±‚** - `geminiService.ts` æ˜¯å”¯ä¸€éœ€è¦æ”¹åŠ¨çš„æ–‡ä»¶
3. **ç±»å‹å®šä¹‰é€šç”¨** - `Message` æ¥å£å®Œå…¨å…¼å®¹å…¶ä»– LLM

**éœ€è¦è°ƒæ•´çš„å†…å®¹ï¼š**

| ç°æœ‰å®ç° | MiniMax | GLM (æ™ºè°±) |
|---------|---------|-----------|
| `GoogleGenAI` | `OpenAI` (MiniMax å…¼å®¹ OpenAI SDK) | `ZhipuAI` |
| `chat.sendMessageStream()` | `client.chat.completions.create()` | åŒå·¦ |
| `model: 'gemini-3-flash'` | `model: 'abab6.5s-chat'` | `model: 'glm-4-flash'` |
| `response.text` | `chunk.choices[0].delta.content` | åŒå·¦ |

#### ğŸ”§ **æ”¹é€ æ–¹æ¡ˆ**

åˆ›å»ºæ–°çš„æœåŠ¡æ–‡ä»¶ï¼Œä¾‹å¦‚ `services/minimaxService.ts`:

```typescript
import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: import.meta.env.VITE_MINIMAX_API_KEY,
  baseURL: 'https://api.minimax.chat/v1/text/chatcompletion_v2'
});

export const sendMessageStream = async (messages: Message[]) => {
  return client.chat.completions.create({
    model: 'abab6.5s-chat',
    messages: [
      { role: 'system', content: SYSTEM_INSTRUCTION },
      ...messages.map(m => ({ role: m.role, content: m.text }))
    ],
    stream: true
  });
};
```

---

### å››ã€ç»“è®º

1. **å‚æ•°ä¼ é€’æ¸…æ™°** - ä»…é€šè¿‡ `message` å­—ç¬¦ä¸²å’Œ `systemInstruction` é…ç½®ä¼ é€’
2. **æ›´æ¢ API å®Œå…¨å¯è¡Œ** - åªéœ€ä¿®æ”¹æœåŠ¡å±‚ï¼ŒUI å’Œä¸šåŠ¡é€»è¾‘æ— éœ€æ”¹åŠ¨
3. **æ¨èæ–¹æ¡ˆ** - å…ˆè¯„ä¼° MiniMax/GLM çš„åŠŸèƒ½æ”¯æŒï¼ˆæµå¼è¾“å‡ºã€å‡½æ•°è°ƒç”¨ç­‰ï¼‰ï¼Œç„¶ååˆ›å»ºé€‚é…å™¨æ¨¡å¼çš„æœåŠ¡ç±»

å¦‚æœæ‚¨å†³å®šæ›´æ¢ APIï¼Œè¯· **toggle to Act mode**ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨å®ç°å®Œæ•´çš„æ”¹é€ ä»£ç ã€‚
